{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpython\u001b[49m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m-\u001b[39mversion\n",
      "\u001b[0;31mNameError\u001b[0m: name 'python' is not defined"
     ]
    }
   ],
   "source": [
    "python --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import SVHN\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the SVHN dataset\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = SVHN(root='./data', split='train', transform=train_transform, download=True)\n",
    "test_dataset = SVHN(root='./data', split='test', transform=test_transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a subset of the dataset (25%)\n",
    "train_subset = Subset(train_dataset, range(0, len(train_dataset), 4))\n",
    "\n",
    "# Step 2: Preprocess the dataset\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Step 3: Choose pretrained models\n",
    "# Implement LeNet-5 manually\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geoai/miniconda3/envs/dla/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/geoai/miniconda3/envs/dla/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/geoai/miniconda3/envs/dla/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/geoai/miniconda3/envs/dla/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/geoai/miniconda3/envs/dla/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LeNet-5, Epoch [1/10], Loss: 2.1673, Accuracy: 21.86%\n",
      "Model: LeNet-5, Epoch [2/10], Loss: 1.7317, Accuracy: 39.02%\n",
      "Model: LeNet-5, Epoch [3/10], Loss: 1.4427, Accuracy: 50.43%\n",
      "Model: LeNet-5, Epoch [4/10], Loss: 1.2872, Accuracy: 56.47%\n",
      "Model: LeNet-5, Epoch [5/10], Loss: 1.1871, Accuracy: 59.97%\n",
      "Model: LeNet-5, Epoch [6/10], Loss: 1.1112, Accuracy: 62.54%\n",
      "Model: LeNet-5, Epoch [7/10], Loss: 1.0548, Accuracy: 64.85%\n",
      "Model: LeNet-5, Epoch [8/10], Loss: 1.0290, Accuracy: 65.34%\n",
      "Model: LeNet-5, Epoch [9/10], Loss: 0.9803, Accuracy: 67.67%\n",
      "Model: LeNet-5, Epoch [10/10], Loss: 0.9488, Accuracy: 68.26%\n",
      "Training finished for LeNet-5\n",
      "Model: VGG-16, Epoch [1/10], Loss: 2.5640, Accuracy: 16.59%\n",
      "Model: VGG-16, Epoch [2/10], Loss: 2.2587, Accuracy: 18.10%\n",
      "Model: VGG-16, Epoch [3/10], Loss: 2.2475, Accuracy: 18.50%\n",
      "Model: VGG-16, Epoch [4/10], Loss: 2.2466, Accuracy: 18.43%\n",
      "Model: VGG-16, Epoch [5/10], Loss: 2.2450, Accuracy: 18.54%\n",
      "Model: VGG-16, Epoch [6/10], Loss: 2.2439, Accuracy: 18.79%\n",
      "Model: VGG-16, Epoch [7/10], Loss: 2.2435, Accuracy: 18.77%\n",
      "Model: VGG-16, Epoch [8/10], Loss: 2.2424, Accuracy: 18.74%\n",
      "Model: VGG-16, Epoch [9/10], Loss: 2.2420, Accuracy: 18.80%\n",
      "Model: VGG-16, Epoch [10/10], Loss: 2.2422, Accuracy: 18.76%\n",
      "Training finished for VGG-16\n",
      "Model: ResNet-18, Epoch [1/10], Loss: 2.1089, Accuracy: 31.06%\n",
      "Model: ResNet-18, Epoch [2/10], Loss: 1.0417, Accuracy: 64.71%\n",
      "Model: ResNet-18, Epoch [3/10], Loss: 0.7979, Accuracy: 74.16%\n",
      "Model: ResNet-18, Epoch [4/10], Loss: 0.6987, Accuracy: 77.49%\n",
      "Model: ResNet-18, Epoch [5/10], Loss: 0.6310, Accuracy: 79.76%\n",
      "Model: ResNet-18, Epoch [6/10], Loss: 0.5905, Accuracy: 81.24%\n",
      "Model: ResNet-18, Epoch [7/10], Loss: 0.5479, Accuracy: 82.93%\n",
      "Model: ResNet-18, Epoch [8/10], Loss: 0.5221, Accuracy: 83.52%\n",
      "Model: ResNet-18, Epoch [9/10], Loss: 0.4915, Accuracy: 84.68%\n",
      "Model: ResNet-18, Epoch [10/10], Loss: 0.4722, Accuracy: 85.26%\n",
      "Training finished for ResNet-18\n",
      "Model: ResNet-50, Epoch [1/10], Loss: 1.5724, Accuracy: 50.33%\n",
      "Model: ResNet-50, Epoch [2/10], Loss: 0.8321, Accuracy: 73.20%\n",
      "Model: ResNet-50, Epoch [3/10], Loss: 0.9969, Accuracy: 69.27%\n",
      "Model: ResNet-50, Epoch [4/10], Loss: 1.3032, Accuracy: 61.87%\n",
      "Model: ResNet-50, Epoch [5/10], Loss: 0.7751, Accuracy: 75.19%\n",
      "Model: ResNet-50, Epoch [6/10], Loss: 0.7836, Accuracy: 75.47%\n",
      "Model: ResNet-50, Epoch [7/10], Loss: 0.7029, Accuracy: 78.32%\n",
      "Model: ResNet-50, Epoch [8/10], Loss: 0.6308, Accuracy: 80.24%\n",
      "Model: ResNet-50, Epoch [9/10], Loss: 0.5480, Accuracy: 82.74%\n",
      "Model: ResNet-50, Epoch [10/10], Loss: 0.6788, Accuracy: 78.90%\n",
      "Training finished for ResNet-50\n",
      "Model: ResNet-101, Epoch [1/10], Loss: 1.8221, Accuracy: 42.52%\n",
      "Model: ResNet-101, Epoch [2/10], Loss: 1.5148, Accuracy: 50.75%\n",
      "Model: ResNet-101, Epoch [3/10], Loss: 1.3553, Accuracy: 55.01%\n",
      "Model: ResNet-101, Epoch [4/10], Loss: 0.9127, Accuracy: 69.34%\n",
      "Model: ResNet-101, Epoch [5/10], Loss: 0.8156, Accuracy: 73.49%\n",
      "Model: ResNet-101, Epoch [6/10], Loss: 0.8167, Accuracy: 73.25%\n",
      "Model: ResNet-101, Epoch [7/10], Loss: 0.6680, Accuracy: 78.21%\n",
      "Model: ResNet-101, Epoch [8/10], Loss: 0.6572, Accuracy: 78.99%\n",
      "Model: ResNet-101, Epoch [9/10], Loss: 0.7910, Accuracy: 75.31%\n",
      "Model: ResNet-101, Epoch [10/10], Loss: 0.7490, Accuracy: 76.12%\n",
      "Training finished for ResNet-101\n"
     ]
    }
   ],
   "source": [
    "pretrained_models = {\n",
    "    'LeNet-5': LeNet5(),\n",
    "    'VGG-16': models.vgg16(pretrained=True),\n",
    "    'ResNet-18': models.resnet18(pretrained=True),\n",
    "    'ResNet-50': models.resnet50(pretrained=True),\n",
    "    'ResNet-101': models.resnet101(pretrained=True)\n",
    "}\n",
    "\n",
    "# Step 4: Load the pretrained weights for the chosen model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Step 5: Fine-tune the model on the SVHN dataset\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize CSV writer\n",
    "with open('model_metrics.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Model', 'Test Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "\n",
    "    for model_name, model in pretrained_models.items():\n",
    "        model = model.to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Training loop with data augmentation and adjusted hyperparameters\n",
    "        model.train()  # Set model to training mode\n",
    "    \n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "          \n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            epoch_loss = running_loss / len(train_loader.dataset)\n",
    "            epoch_acc = correct / total * 100\n",
    "            \n",
    "            print(f\"Model: {model_name}, Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "    \n",
    "        print(\"Training finished for\", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for ResNet-101: 83.92%\n",
      "Performance Report for ResNet-101:\n",
      "--------------------------------------------------\n",
      "Test Accuracy: 83.92%\n",
      "Precision: 0.8457\n",
      "Recall: 0.8196\n",
      "F1-score: 0.8278\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval() \n",
    "correct = 0\n",
    "total = 0\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_accuracy = correct / total * 100\n",
    "print(f\"Test Accuracy for {model_name}: {test_accuracy:.2f}%\")\n",
    "\n",
    "precision = precision_score(true_labels, predicted_labels, average='macro')\n",
    "recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "print(f\"Performance Report for {model_name}:\")\n",
    "print(\"--------------------------------------------------\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(\"--------------------------------------------------\")\n",
    "print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
